{
  "name": "sample-models",
  "description": "Example model configurations for common AI services",
  "models": [
    {
      "name": "OpenAI GPT-4",
      "description": "Most capable GPT model, great for complex reasoning tasks",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "modelType": "llm",
      "owner": "OpenAI",
      "latency": 2000,
      "costPerToken": 0.00003,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "enum": ["gpt-4", "gpt-4-turbo", "gpt-4-turbo-preview"]
          },
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string",
                  "enum": ["system", "user", "assistant"]
                },
                "content": {
                  "type": "string"
                }
              },
              "required": ["role", "content"]
            }
          },
          "temperature": {
            "type": "number",
            "minimum": 0,
            "maximum": 2,
            "default": 1
          },
          "max_tokens": {
            "type": "integer",
            "minimum": 1,
            "maximum": 4096
          }
        },
        "required": ["model", "messages"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "object": {"type": "string"},
          "created": {"type": "integer"},
          "model": {"type": "string"},
          "choices": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "index": {"type": "integer"},
                "message": {
                  "type": "object",
                  "properties": {
                    "role": {"type": "string"},
                    "content": {"type": "string"}
                  }
                },
                "finish_reason": {"type": "string"}
              }
            }
          },
          "usage": {
            "type": "object",
            "properties": {
              "prompt_tokens": {"type": "integer"},
              "completion_tokens": {"type": "integer"},
              "total_tokens": {"type": "integer"}
            }
          }
        }
      },
      "tags": ["openai", "gpt-4", "language-model", "reasoning"],
      "healthCheckUrl": "https://api.openai.com/v1/models",
      "apiKey": "${OPENAI_API_KEY}"
    },
    {
      "name": "OpenAI GPT-3.5 Turbo",
      "description": "Fast and efficient model for most conversational tasks",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "modelType": "llm",
      "owner": "OpenAI",
      "latency": 1000,
      "costPerToken": 0.000002,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "enum": ["gpt-3.5-turbo", "gpt-3.5-turbo-16k"]
          },
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": {"type": "string"},
                "content": {"type": "string"}
              }
            }
          },
          "temperature": {"type": "number", "minimum": 0, "maximum": 2},
          "max_tokens": {"type": "integer", "minimum": 1}
        },
        "required": ["model", "messages"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "choices": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "message": {
                  "type": "object",
                  "properties": {
                    "content": {"type": "string"}
                  }
                }
              }
            }
          }
        }
      },
      "tags": ["openai", "gpt-3.5", "language-model", "fast"],
      "apiKey": "${OPENAI_API_KEY}"
    },
    {
      "name": "OpenAI DALL-E 3",
      "description": "Advanced image generation from text descriptions",
      "endpoint": "https://api.openai.com/v1/images/generations",
      "modelType": "vision",
      "owner": "OpenAI",
      "latency": 15000,
      "costPerToken": 0.04,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "enum": ["dall-e-3", "dall-e-2"]
          },
          "prompt": {
            "type": "string",
            "maxLength": 4000
          },
          "n": {
            "type": "integer",
            "minimum": 1,
            "maximum": 1,
            "default": 1
          },
          "quality": {
            "type": "string",
            "enum": ["standard", "hd"],
            "default": "standard"
          },
          "size": {
            "type": "string",
            "enum": ["1024x1024", "1024x1792", "1792x1024"],
            "default": "1024x1024"
          }
        },
        "required": ["model", "prompt"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "created": {"type": "integer"},
          "data": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "url": {"type": "string"},
                "revised_prompt": {"type": "string"}
              }
            }
          }
        }
      },
      "tags": ["openai", "dall-e", "image-generation", "vision"],
      "apiKey": "${OPENAI_API_KEY}"
    },
    {
      "name": "HuggingFace BERT Base",
      "description": "General-purpose language understanding model",
      "endpoint": "https://api-inference.huggingface.co/models/bert-base-uncased",
      "modelType": "embedding",
      "owner": "HuggingFace",
      "latency": 2500,
      "costPerToken": 0,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "inputs": {
            "type": "string",
            "maxLength": 512
          },
          "options": {
            "type": "object",
            "properties": {
              "wait_for_model": {"type": "boolean", "default": false},
              "use_cache": {"type": "boolean", "default": true}
            }
          }
        },
        "required": ["inputs"]
      },
      "outputSchema": {
        "type": "array",
        "items": {
          "type": "number"
        }
      },
      "tags": ["huggingface", "bert", "embedding", "nlp"],
      "apiKey": "${HUGGINGFACE_API_KEY}"
    },
    {
      "name": "Anthropic Claude 3",
      "description": "Advanced conversational AI with strong reasoning capabilities",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "modelType": "llm",
      "owner": "Anthropic",
      "latency": 2500,
      "costPerToken": 0.000015,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "enum": ["claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
          },
          "max_tokens": {
            "type": "integer",
            "minimum": 1,
            "maximum": 4096
          },
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": {"type": "string", "enum": ["user", "assistant"]},
                "content": {"type": "string"}
              }
            }
          },
          "temperature": {"type": "number", "minimum": 0, "maximum": 1}
        },
        "required": ["model", "max_tokens", "messages"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "type": {"type": "string"},
          "role": {"type": "string"},
          "content": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "type": {"type": "string"},
                "text": {"type": "string"}
              }
            }
          },
          "usage": {
            "type": "object",
            "properties": {
              "input_tokens": {"type": "integer"},
              "output_tokens": {"type": "integer"}
            }
          }
        }
      },
      "tags": ["anthropic", "claude", "language-model", "reasoning"],
      "apiKey": "${ANTHROPIC_API_KEY}"
    },
    {
      "name": "Local Ollama LLaMA 2",
      "description": "Open-source language model running locally",
      "endpoint": "http://localhost:11434/api/generate",
      "modelType": "llm",
      "owner": "Local",
      "latency": 5000,
      "costPerToken": 0,
      "securityPolicy": "private",
      "inputSchema": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "enum": ["llama2", "llama2:13b", "llama2:70b"]
          },
          "prompt": {"type": "string"},
          "stream": {"type": "boolean", "default": false},
          "options": {
            "type": "object",
            "properties": {
              "temperature": {"type": "number", "minimum": 0, "maximum": 1},
              "top_p": {"type": "number", "minimum": 0, "maximum": 1},
              "top_k": {"type": "integer", "minimum": 1}
            }
          }
        },
        "required": ["model", "prompt"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "model": {"type": "string"},
          "created_at": {"type": "string"},
          "response": {"type": "string"},
          "done": {"type": "boolean"},
          "context": {"type": "array"},
          "total_duration": {"type": "integer"},
          "load_duration": {"type": "integer"},
          "prompt_eval_count": {"type": "integer"},
          "prompt_eval_duration": {"type": "integer"},
          "eval_count": {"type": "integer"},
          "eval_duration": {"type": "integer"}
        }
      },
      "tags": ["ollama", "llama2", "local", "open-source"],
      "healthCheckUrl": "http://localhost:11434/api/tags"
    },
    {
      "name": "Google Gemini Pro",
      "description": "Google's multimodal AI model",
      "endpoint": "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
      "modelType": "llm",
      "owner": "Google",
      "latency": 3000,
      "costPerToken": 0.000125,
      "securityPolicy": "public",
      "inputSchema": {
        "type": "object",
        "properties": {
          "contents": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "parts": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "text": {"type": "string"}
                    }
                  }
                }
              }
            }
          },
          "generationConfig": {
            "type": "object",
            "properties": {
              "temperature": {"type": "number", "minimum": 0, "maximum": 1},
              "topK": {"type": "integer", "minimum": 1},
              "topP": {"type": "number", "minimum": 0, "maximum": 1},
              "maxOutputTokens": {"type": "integer", "minimum": 1}
            }
          }
        },
        "required": ["contents"]
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "candidates": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "content": {
                  "type": "object",
                  "properties": {
                    "parts": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "text": {"type": "string"}
                        }
                      }
                    },
                    "role": {"type": "string"}
                  }
                }
              }
            }
          }
        }
      },
      "tags": ["google", "gemini", "multimodal", "language-model"],
      "apiKey": "${GOOGLE_API_KEY}"
    }
  ],
  "pipelines": [
    {
      "name": "Content Enhancement Pipeline",
      "description": "Generate initial content with GPT-4, then enhance with Claude for better quality",
      "nodes": [
        {
          "id": "generator",
          "modelName": "OpenAI GPT-4",
          "position": {"x": 100, "y": 100},
          "config": {
            "temperature": 0.8,
            "max_tokens": 1000,
            "systemPrompt": "You are a creative content generator. Generate engaging, original content based on the user's request."
          }
        },
        {
          "id": "enhancer", 
          "modelName": "Anthropic Claude 3",
          "position": {"x": 400, "y": 100},
          "config": {
            "temperature": 0.3,
            "max_tokens": 1500,
            "systemPrompt": "You are an expert editor. Improve the given content by enhancing clarity, flow, and engagement while maintaining the original intent."
          }
        }
      ],
      "edges": [
        {
          "id": "gen-to-enhance",
          "source": "generator",
          "target": "enhancer"
        }
      ]
    },
    {
      "name": "Multi-Language Translation Chain",
      "description": "Translate content through multiple languages for quality improvement",
      "nodes": [
        {
          "id": "translator1",
          "modelName": "OpenAI GPT-4",
          "position": {"x": 100, "y": 100},
          "config": {
            "systemPrompt": "You are a professional translator. Translate the given text to French, maintaining nuance and context."
          }
        },
        {
          "id": "translator2",
          "modelName": "Google Gemini Pro",
          "position": {"x": 300, "y": 100},
          "config": {
            "systemPrompt": "You are a professional translator. Translate the given French text back to English, improving clarity."
          }
        }
      ],
      "edges": [
        {
          "id": "t1-to-t2",
          "source": "translator1",
          "target": "translator2"
        }
      ]
    },
    {
      "name": "Image Analysis and Description",
      "description": "Generate images and create detailed descriptions",
      "nodes": [
        {
          "id": "image_gen",
          "modelName": "OpenAI DALL-E 3", 
          "position": {"x": 100, "y": 100},
          "config": {
            "quality": "hd",
            "size": "1024x1024"
          }
        },
        {
          "id": "description",
          "modelName": "OpenAI GPT-4",
          "position": {"x": 400, "y": 100},
          "config": {
            "systemPrompt": "You are an art critic. Provide a detailed, insightful description of the given image."
          }
        }
      ],
      "edges": [
        {
          "id": "img-to-desc",
          "source": "image_gen",
          "target": "description"
        }
      ]
    }
  ],
  "configuration": {
    "defaultRetries": 3,
    "defaultTimeout": 30000,
    "healthCheckInterval": 300000,
    "costTrackingEnabled": true,
    "analyticsRetention": "30d"
  }
}